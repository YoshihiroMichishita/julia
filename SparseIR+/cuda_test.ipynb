{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Attention{I <: Integer, O, F1 <: AbstractArray, F2 <: AbstractArray}\n",
    "    d_in::I\n",
    "    d_k::I\n",
    "    d_out::I\n",
    "    sqrt_d_k::O\n",
    "    \n",
    "    Wq::F1\n",
    "    Wk::F1\n",
    "    Wv::F1\n",
    "    bv::F2\n",
    "end\n",
    "\n",
    "\n",
    "function Attention(d_in::Int, d_k::Int, d_out::Int)\n",
    "    sqrt_d = Float32(sqrt(d_k))\n",
    "    Wq = randn(Float32, d_out, d_in)\n",
    "    Wk = randn(Float32, d_k, d_in)\n",
    "    Wv = randn(Float32, d_k, d_in)\n",
    "    bv = randn(Float32, d_out)\n",
    "    return Attention(d_in, d_k, d_out, sqrt_d, Wq, Wk, Wv, bv)\n",
    "end\n",
    "\n",
    "struct RMSLayerNorm{F} #<: AbstractArray\n",
    "    #d_in::I\n",
    "    g::F\n",
    "end\n",
    "\n",
    "function RMSLayerNorm(d_in::Int)\n",
    "    g = ones(Float32, d_in)\n",
    "    return RMSLayerNorm(g)\n",
    "end\n",
    "\n",
    "Flux.trainable(a::Attention) = (Wq=a.Wq, Wk = a.Wk, Wv= a.Wv, b=a.bv)\n",
    "\n",
    "Flux.trainable(a::RMSLayerNorm) = (; g = a.g)\n",
    "\n",
    "function (m::Attention)(x::AbstractArray)\n",
    "    q = m.Wq * x\n",
    "    k = m.Wk * x\n",
    "    v = m.Wv * x\n",
    "    a = softmax(q' * k / m.sqrt_d_k, dims=2)\n",
    "    #a = softmax(q * k')\n",
    "    return a * v .+ m.bv\n",
    "end\n",
    "\n",
    "function (m::RMSLayerNorm)(x::AbstractArray)\n",
    "    return Diagonal(m.g) * x / Diagonal(sqrt.(vec(mean(x.^2, dims=1))))\n",
    "end\n",
    "\n",
    "Flux.@layer Attention\n",
    "#Flux.@functor RMSLayerNorm\n",
    "Flux.@layer RMSLayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(5 => 5),                        \u001b[90m# 30 parameters\u001b[39m\n",
       "  RMSLayerNorm{CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}(Float32[1.0, 1.0, 1.0, 1.0, 1.0]),  \u001b[90m# 5 parameters\u001b[39m\n",
       "  NNlib.tanh_fast,\n",
       ") \u001b[90m                  # Total: 3 arrays, \u001b[39m35 parameters, 512 bytes."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Chain(Dense(5,5), RMSLayerNorm(5), tanh_fast) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×20 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 0.710282  0.468841  0.155123   0.984254  …  0.659424  0.70125    0.575374\n",
       " 0.858692  0.511139  0.0676039  0.292649     0.177536  0.591967   0.928848\n",
       " 0.169994  0.255369  0.972712   0.274113     0.556985  0.0961319  0.0833815\n",
       " 0.489282  0.429942  0.206087   0.937918     0.233601  0.517326   0.701799\n",
       " 0.583291  0.703098  0.819706   0.089069     0.506761  0.613294   0.445674"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = cu(rand(Float32, 5, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×20 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       "  0.602715   0.457042   0.288227  …   0.70698    0.579766   0.41954\n",
       " -0.913179  -0.891117  -0.848338     -0.865343  -0.891189  -0.907478\n",
       "  0.754435   0.761685   0.623224      0.521342   0.749178   0.818099\n",
       "  0.360557   0.627924   0.574335      0.671513   0.678817   0.326798\n",
       "  0.764369   0.794513   0.913013      0.841089   0.738366   0.77582"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×10 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 0.690286  0.659953  0.444712  0.559699  …  0.48145  0.452321  0.443771"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test2 = mean(test, dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 0.6902859\n",
       " 0.6599535\n",
       " 0.4447119\n",
       " 0.5596994\n",
       " 0.46951193\n",
       " 0.4326908\n",
       " 0.47565067\n",
       " 0.48144966\n",
       " 0.45232105\n",
       " 0.44377148"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test3 = vec(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "Scalar indexing is disallowed.\nInvocation of getindex resulted in scalar indexing of a GPU array.\nThis is typically caused by calling an iterating implementation of a method.\nSuch implementations *do not* execute on the GPU, but very slowly on the CPU,\nand therefore should be avoided.\n\nIf you want to allow scalar iteration, use `allowscalar` or `@allowscalar`\nto enable scalar iteration globally or for the operations in question.",
     "output_type": "error",
     "traceback": [
      "Scalar indexing is disallowed.\n",
      "Invocation of getindex resulted in scalar indexing of a GPU array.\n",
      "This is typically caused by calling an iterating implementation of a method.\n",
      "Such implementations *do not* execute on the GPU, but very slowly on the CPU,\n",
      "and therefore should be avoided.\n",
      "\n",
      "If you want to allow scalar iteration, use `allowscalar` or `@allowscalar`\n",
      "to enable scalar iteration globally or for the operations in question.\n",
      "\n",
      "Stacktrace:\n",
      "  [1] error(s::String)\n",
      "    @ Base ./error.jl:35\n",
      "  [2] errorscalar(op::String)\n",
      "    @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:155\n",
      "  [3] _assertscalar(op::String, behavior::GPUArraysCore.ScalarIndexing)\n",
      "    @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:128\n",
      "  [4] assertscalar(op::String)\n",
      "    @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:116\n",
      "  [5] getindex\n",
      "    @ ~/.julia/packages/GPUArrays/HjWFN/src/host/indexing.jl:48 [inlined]\n",
      "  [6] getindex\n",
      "    @ ~/.julia/juliaup/julia-1.10.4+0.x64.linux.gnu/share/julia/stdlib/v1.10/LinearAlgebra/src/diagonal.jl:156 [inlined]\n",
      "  [7] _getindex\n",
      "    @ ./abstractarray.jl:1341 [inlined]\n",
      "  [8] getindex\n",
      "    @ ./abstractarray.jl:1291 [inlined]\n",
      "  [9] iterate\n",
      "    @ ./abstractarray.jl:1217 [inlined]\n",
      " [10] iterate\n",
      "    @ ./abstractarray.jl:1215 [inlined]\n",
      " [11] params!(p::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}}, x::RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}, seen::Base.IdSet{Any})\n",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/functor.jl:86\n",
      " [12] params!\n",
      "    @ ~/.julia/packages/Flux/Wz6D4/src/functor.jl:87 [inlined]\n",
      " [13] params!\n",
      "    @ ~/.julia/packages/Flux/Wz6D4/src/functor.jl:79 [inlined]\n",
      " [14] params(m::RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}})\n",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/functor.jl:127\n",
      " [15] _layer_show(io::IO, layer::Any, indent::Int64, name::Any)\n",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/show.jl:93\n",
      " [16] _big_show\n",
      "    @ ~/.julia/packages/Flux/Wz6D4/src/layers/show.jl:85 [inlined]\n",
      " [17] _big_show(io::IOContext{IOBuffer}, obj::RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}, indent::Int64)\n",
      "    @ Main ~/.julia/packages/Flux/Wz6D4/src/layers/show.jl:85\n",
      " [18] _big_show(io::IO, obj::Any, indent::Int64, name::Any)\n",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/show.jl:43\n",
      " [19] _big_show\n",
      "    @ ~/.julia/packages/Flux/Wz6D4/src/layers/show.jl:23 [inlined]\n",
      " [20] show(io::IOContext{IOBuffer}, m::MIME{Symbol(\"text/plain\")}, x::Chain{Tuple{Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}})\n",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/show.jl:9\n",
      " [21] limitstringmime(mime::MIME{Symbol(\"text/plain\")}, x::Chain{Tuple{Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}})\n",
      "    @ VSCodeServer.IJuliaCore ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/IJuliaCore/src/inline.jl:22\n",
      " [22] display_mimestring(m::MIME{Symbol(\"text/plain\")}, x::Chain{Tuple{Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}})\n",
      "    @ VSCodeServer.IJuliaCore ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/IJuliaCore/src/display.jl:67\n",
      " [23] display_dict(x::Chain{Tuple{Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}})\n",
      "    @ VSCodeServer.IJuliaCore ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/IJuliaCore/src/display.jl:98\n",
      " [24] display(::VSCodeServer.JuliaNotebookInlineDisplay, x::Chain{Tuple{Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}})\n",
      "    @ VSCodeServer ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/notebookdisplay.jl:32\n",
      " [25] display(x::Any)\n",
      "    @ Base.Multimedia ./multimedia.jl:340\n",
      " [26] #invokelatest#2\n",
      "    @ ./essentials.jl:892 [inlined]\n",
      " [27] invokelatest\n",
      "    @ ./essentials.jl:889 [inlined]\n",
      " [28] (::VSCodeServer.var\"#219#220\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:48\n",
      " [29] withpath(f::VSCodeServer.var\"#219#220\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/repl.jl:276\n",
      " [30] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, params::VSCodeServer.NotebookRunCellArguments)\n",
      "    @ VSCodeServer ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:13\n",
      " [31] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::Dict{String, Any})\n",
      "    @ VSCodeServer.JSONRPC ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/JSONRPC/src/typed.jl:67\n",
      " [32] serve_notebook(pipename::String, outputchannel_logger::Base.CoreLogging.SimpleLogger; crashreporting_pipename::String)\n",
      "    @ VSCodeServer ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:139\n",
      " [33] top-level scope\n",
      "    @ ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/notebook/notebook.jl:35"
     ]
    }
   ],
   "source": [
    "model = Chain(Dense(20,20), RMSLayerNorm(20)) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}(Float32[1.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 0.0 1.0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = RMSLayerNorm(20) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(20 => 20)     \u001b[90m# 420 parameters\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = Dense(20,20) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "Scalar indexing is disallowed.\nInvocation of getindex resulted in scalar indexing of a GPU array.\nThis is typically caused by calling an iterating implementation of a method.\nSuch implementations *do not* execute on the GPU, but very slowly on the CPU,\nand therefore should be avoided.\n\nIf you want to allow scalar iteration, use `allowscalar` or `@allowscalar`\nto enable scalar iteration globally or for the operations in question.",
     "output_type": "error",
     "traceback": [
      "Scalar indexing is disallowed.\n",
      "Invocation of getindex resulted in scalar indexing of a GPU array.\n",
      "This is typically caused by calling an iterating implementation of a method.\n",
      "Such implementations *do not* execute on the GPU, but very slowly on the CPU,\n",
      "and therefore should be avoided.\n",
      "\n",
      "If you want to allow scalar iteration, use `allowscalar` or `@allowscalar`\n",
      "to enable scalar iteration globally or for the operations in question.\n",
      "\n",
      "Stacktrace:\n",
      "  [1] error(s::String)\n",
      "    @ Base ./error.jl:35\n",
      "  [2] errorscalar(op::String)\n",
      "    @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:155\n",
      "  [3] _assertscalar(op::String, behavior::GPUArraysCore.ScalarIndexing)\n",
      "    @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:128\n",
      "  [4] assertscalar(op::String)\n",
      "    @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:116\n",
      "  [5] getindex\n",
      "    @ ~/.julia/packages/GPUArrays/HjWFN/src/host/indexing.jl:48 [inlined]\n",
      "  [6] getindex\n",
      "    @ ~/.julia/juliaup/julia-1.10.4+0.x64.linux.gnu/share/julia/stdlib/v1.10/LinearAlgebra/src/diagonal.jl:156 [inlined]\n",
      "  [7] _getindex\n",
      "    @ ./abstractarray.jl:1341 [inlined]\n",
      "  [8] getindex\n",
      "    @ ./abstractarray.jl:1291 [inlined]\n",
      "  [9] iterate\n",
      "    @ ./abstractarray.jl:1217 [inlined]\n",
      " [10] iterate\n",
      "    @ ./abstractarray.jl:1215 [inlined]\n",
      " [11] params!(p::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}}, x::RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}, seen::Base.IdSet{Any})\n",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/functor.jl:86\n",
      " [12] params!\n",
      "    @ ~/.julia/packages/Flux/Wz6D4/src/functor.jl:87 [inlined]\n",
      " [13] params!\n",
      "    @ ~/.julia/packages/Flux/Wz6D4/src/functor.jl:79 [inlined]\n",
      " [14] params(m::RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}})\n",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/functor.jl:127\n",
      " [15] _layer_show(io::IO, layer::Any, indent::Int64, name::Any)\n",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/show.jl:93\n",
      " [16] _big_show(io::IO, obj::Any, indent::Int64, name::Any)\n",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/show.jl:28\n",
      " [17] _big_show(io::IO, obj::Any, indent::Int64)\n",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/show.jl:23\n",
      " [18] _big_show(io::IO, obj::Any, indent::Int64, name::Any)\n",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/show.jl:43\n",
      " [19] _big_show\n",
      "    @ ~/.julia/packages/Flux/Wz6D4/src/layers/show.jl:23 [inlined]\n",
      " [20] show(io::IOContext{IOBuffer}, m::MIME{Symbol(\"text/plain\")}, x::Chain{Tuple{Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}})\n",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/show.jl:9\n",
      " [21] limitstringmime(mime::MIME{Symbol(\"text/plain\")}, x::Chain{Tuple{Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}})\n",
      "    @ VSCodeServer.IJuliaCore ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/IJuliaCore/src/inline.jl:22\n",
      " [22] display_mimestring(m::MIME{Symbol(\"text/plain\")}, x::Chain{Tuple{Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}})\n",
      "    @ VSCodeServer.IJuliaCore ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/IJuliaCore/src/display.jl:67\n",
      " [23] display_dict(x::Chain{Tuple{Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}})\n",
      "    @ VSCodeServer.IJuliaCore ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/IJuliaCore/src/display.jl:98\n",
      " [24] display(::VSCodeServer.JuliaNotebookInlineDisplay, x::Chain{Tuple{Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, RMSLayerNorm{Diagonal{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}})\n",
      "    @ VSCodeServer ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/notebookdisplay.jl:32\n",
      " [25] display(x::Any)\n",
      "    @ Base.Multimedia ./multimedia.jl:340\n",
      " [26] #invokelatest#2\n",
      "    @ ./essentials.jl:892 [inlined]\n",
      " [27] invokelatest\n",
      "    @ ./essentials.jl:889 [inlined]\n",
      " [28] (::VSCodeServer.var\"#219#220\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:48\n",
      " [29] withpath(f::VSCodeServer.var\"#219#220\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/repl.jl:276\n",
      " [30] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, params::VSCodeServer.NotebookRunCellArguments)\n",
      "    @ VSCodeServer ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:13\n",
      " [31] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::Dict{String, Any})\n",
      "    @ VSCodeServer.JSONRPC ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/JSONRPC/src/typed.jl:67\n",
      " [32] serve_notebook(pipename::String, outputchannel_logger::Base.CoreLogging.SimpleLogger; crashreporting_pipename::String)\n",
      "    @ VSCodeServer ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:139\n",
      " [33] top-level scope\n",
      "    @ ~/.vscode-server/extensions/julialang.language-julia-1.79.2/scripts/notebook/notebook.jl:35"
     ]
    }
   ],
   "source": [
    "model_tot = Chain(model1, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20×10 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       "  0.112839    0.293395  -0.492453  …  -0.286902    0.352718    0.22967\n",
       "  0.708213   -2.03752   -1.18512       1.55661     0.33228    -1.6682\n",
       "  0.858796   -0.779169   0.393398      1.50495    -0.430251    0.71641\n",
       "  0.516096   -0.788281  -1.11363      -0.405662   -0.272435   -0.237644\n",
       " -2.60874    -1.04056    0.432863     -1.47429    -1.09094    -0.832609\n",
       "  1.10736    -1.40061   -0.140503  …  -0.575804   -0.535272   -1.04574\n",
       " -1.06602    -0.528929  -0.720663      0.319153   -0.460791   -1.03256\n",
       "  1.08024     0.382457   1.46068      -1.42958    -0.670673    0.0583352\n",
       "  0.483158   -1.34547    0.66802      -0.400428   -1.59719    -1.3818\n",
       "  1.60576     0.216369   0.212982     -0.240003    0.336564   -0.347004\n",
       "  1.89623     0.68115    1.09173   …  -0.902484    0.528603   -0.69045\n",
       "  1.93298    -0.384858  -1.26968       0.602897   -1.32293    -0.51338\n",
       "  1.29343    -0.140246  -0.851839      0.0135565  -0.890413    0.645362\n",
       "  0.100368   -1.28824   -0.388651     -0.857271    0.0210713   1.13613\n",
       "  0.0948362  -2.28222   -1.29695       0.571452   -0.214485    1.25825\n",
       " -0.136306   -0.106298   0.299068  …  -0.338044    2.31213    -0.121296\n",
       " -0.498472   -0.688406   1.18752       1.09048     0.116974    0.485061\n",
       " -0.684508   -0.39488    0.283475      1.09994     1.48129     1.57892\n",
       "  0.30748    -0.26017    1.21032       0.557063    0.248052    0.0604009\n",
       " -0.164683   -0.511799  -0.261482     -0.277064   -2.0758     -0.162032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = randn(Float32, 20, 10) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20×10 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       "  0.101854    0.298945  -0.571124  …  -0.331914    0.351924    0.264362\n",
       "  0.639269   -2.07606   -1.37445       1.80082     0.331532   -1.92019\n",
       "  0.775193   -0.793907   0.456245      1.74106    -0.429282    0.824626\n",
       "  0.465854   -0.803192  -1.29154      -0.469305   -0.271821   -0.273541\n",
       " -2.35478    -1.06024    0.502015     -1.70559    -1.08849    -0.958378\n",
       "  0.999559   -1.42711   -0.162949  …  -0.66614    -0.534067   -1.2037\n",
       " -0.962245   -0.538934  -0.835792      0.369224   -0.459753   -1.18854\n",
       "  0.975083    0.389692   1.69403      -1.65386    -0.669163    0.067147\n",
       "  0.436123   -1.37092    0.774739     -0.46325    -1.59359    -1.59053\n",
       "  1.44944     0.220462   0.247007     -0.277656    0.335806   -0.39942\n",
       "  1.71163     0.694034   1.26614   …  -1.04407     0.527412   -0.794746\n",
       "  1.7448     -0.392137  -1.47251       0.697484   -1.31995    -0.590929\n",
       "  1.16751    -0.142899  -0.987924      0.0156834  -0.888408    0.742846\n",
       "  0.090597   -1.31261   -0.450739     -0.991765    0.0210239   1.30775\n",
       "  0.0856039  -2.32539   -1.50414       0.661105   -0.214002    1.44831\n",
       " -0.123037   -0.108308   0.346846  …  -0.391079    2.30692    -0.139618\n",
       " -0.449946   -0.701427   1.37723       1.26156     0.11671     0.558331\n",
       " -0.617871   -0.402349   0.328762      1.2725      1.47795     1.81743\n",
       "  0.277547   -0.265091   1.40367       0.644459    0.247494    0.0695247\n",
       " -0.148651   -0.52148   -0.303255     -0.320531   -2.07112    -0.186508"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
